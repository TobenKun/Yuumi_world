---
{"dg-publish":true,"permalink":"/CODING/Python/001.30 3장 정리/","noteIcon":"2"}
---

## 이번 장에서 배운 내용

**신경망에서는 활성화 함수로 시그모이드 함수와 ReLU 함수 같은 매끄럽게 변화하는 함수를 이용한다.**
- 퍼셉트론에서는 0 또는 1만 나오는 계단 함수를 활성화 함수로 사용한다.
- 신경망에서는 활성화 함수로 선형함수를 사용해선 안된다.
  -> 선형 함수를 이용하면 신경망의 층을 깊게 하는 의미가 없어짐
  ex) `h(x) = cx`를 활성화 함수로 사용한 3층 네트워크 ->
  `y(x) = h(h(h(x)))` -> `y(x) = c * c * c* x` -> `y(x) = ax`와 같은 꼴
- 최근에는 ReLU함수를 많이 이용한다.

**넘파이의 다차원 배열을 잘 사용하면 신경망을 효율적으로 구현할 수 있다.**

**기계학습 문제는 크게 회귀와 분류로 나눌 수 있다.**
- 분류(classification): 데이터가 어느 클래스에 속하는지
  ex) 사진 속 인물의 성별을 분류하는 문제
- 회귀(regression): 입력 데이터에서 (연속적인) 수치를 예측
  ex) 사진 속 인물의 몸무게를 예측하는 문제

**출력층의 활성화 함수로는 회귀에서는 주로 항등 함수를, 분류에서는 주로 소프트맥스 함수를 이용한다.**
- 소프트맥스의 출력의 합은 항상 1이기 때문에 함수의 출력을 확률로 해석할 수 있다.
- 신경망으로 분류할 때는 출력층의 소프트맥스 함수를 생략해도 된다.
- 신경망을 학습시킬 때는 출력층에서 소프트맥스 함수를 사용한다.
- [[CODING/Python/001.31 소프트맥스 함수에 대한 고찰\|001.31 소프트맥스 함수에 대한 고찰]]

**분류에서는 출력층의 뉴런 수를 분류하려는 클래스 수와 같게 설정한다**
- 출력층 뉴런이 결국 각 클래스로 분류될 확률이 되는것

**입력 데이터를 묶은 것을 배치라 하며, 추론 처리를 이 배치 단위로 진행하면 결과를 훨씬 빠르게 얻을 수 있다.**
- 컴퓨터에서는 큰 배열을 한꺼번에 계산하는 것이 분할된 작은 배열을 여러 번 계산하는 것보다 빠르다.
- [[CODING/Python/001.32 배치 처리\|001.32 배치 처리]]

